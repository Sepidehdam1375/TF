{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbUyKM1bvNHPTokaBhrx7M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sepidehdam1375/TF/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1**. **Libraries**"
      ],
      "metadata": {
        "id": "hkg5ZXCCvP9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEQQfTlt9dgr",
        "outputId": "1be9c875-cdfa-4b34-e9a7-1dee860da67f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2**. **Data** **Preprocessing**"
      ],
      "metadata": {
        "id": "nwXfpUI2vhNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw = load_iris()\n",
        "data_raw.keys()\n",
        "X = data_raw['data']\n",
        "Y = data_raw['target']\n",
        "print(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "Y = np.array(pd.get_dummies(Y, drop_first=False))\n",
        "X = scale(X)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.3, random_state= 3)\n",
        "n_train_size = Y_train.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv9u5MdrJ5S9",
        "outputId": "b29f2306-6167-41fa-9442-2e774604e19d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "(150, 4)\n",
            "(150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3**. **Primary** **Definitions**"
      ],
      "metadata": {
        "id": "zvRY0fo4vwBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_epochs = 30000\n",
        "learn_rate = 0.05\n",
        "w = tf.Variable(tf.ones([4,3]))\n",
        "b = tf.Variable(tf.ones([3]))\n",
        "X_ph = tf.placeholder(tf.float32, shape=(None,4))\n",
        "Y_ph = tf.placeholder(tf.float32, shape=(None,3))\n",
        "Y_model = tf.matmul(X_ph, w) + b\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels= Y_ph, logits= Y_model))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learn_rate)\n",
        "train = optimizer.minimize(loss)\n",
        "init = tf.global_variables_initializer()"
      ],
      "metadata": {
        "id": "coleOHojgGqv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4**. **Training** **and** **Testing**"
      ],
      "metadata": {
        "id": "gTd9BGLDv3YV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for i in range(n_epochs):\n",
        "    idx_rnd = np.random.choice(range(n_train_size), batch_size, replace= False)\n",
        "    batch_x, batch_y = [X_train[idx_rnd,:], Y_train[idx_rnd,:]]\n",
        "    my_feed = {X_ph : batch_x, Y_ph : batch_y}\n",
        "    sess.run(train, feed_dict = my_feed)\n",
        "    if (i + 1)%2000 == 0: print('step: {}'.format(i+1))\n",
        "\n",
        "  correct_predictions = tf.equal(tf.argmax(Y_ph, axis=1), tf.argmax(Y_model, axis=1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "  accuracy_value = sess.run(accuracy, feed_dict={X_ph:X_test, Y_ph:Y_test})\n",
        "\n",
        "  \n",
        "print(\"Accuracy = {:5.3f}\".format(accuracy_value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcElRTBnvMgm",
        "outputId": "01bbd9d7-bbfa-4f8c-ceba-458908751dac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 2000\n",
            "step: 4000\n",
            "step: 6000\n",
            "step: 8000\n",
            "step: 10000\n",
            "step: 12000\n",
            "step: 14000\n",
            "step: 16000\n",
            "step: 18000\n",
            "step: 20000\n",
            "step: 22000\n",
            "step: 24000\n",
            "step: 26000\n",
            "step: 28000\n",
            "step: 30000\n",
            "Accuracy = 0.933\n"
          ]
        }
      ]
    }
  ]
}